{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Network Analysis \n",
    "    \n",
    "## Graph Embeddings\n",
    "\n",
    "\n",
    "by \n",
    "\n",
    "[__Michael Granitzer__ (michael.granitzer@uni-passau.de)]( http://mgrani.github.io/)\n",
    "\n",
    "\n",
    "__License__\n",
    "\n",
    "This work is licensed under a [Creative Commons Attribution 3.0 Unported License](http://creativecommons.org/licenses/by/3.0/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"definition\">\n",
    "**Definition Graph Embedding:** Let $G=(V,E)$ be a graph consisting of a set of vertices $V=\\{v_1\\ldots v_n\\}$ and a set of edges $E=\\{(v_i, v_k)| v_i \\in V\\land v_k \\in V\\}$. A graph embedding $\\mathop{p}$ is defined as function that assignes every vertex of a graph a $d$-dimensional vector $u_i$, i.e. $\\mathop{u}:V \\rightarrow \\Re^d$. We call the resulting vector space $U=\\{u_i| \\forall_{v_i \\in V} u_i = u(v_i) \\}$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- We do not make any assumption on the properties of the embeddings. \n",
    "- We do not explicit restrict the graph to be directed, undirected or weighted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applications:** Embeddings can be understood as a different kind of representation of a graph, opening up a wider field of analysis tools. Examples are\n",
    "- Supervised Learning (e.g. Classification)\n",
    "- Unsupervised Learning\n",
    "- Visualisation (in case of low dimensional embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance-based Manifold Learning for Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MDS, LLE, ISOMAP, Laplacian Eigenmaps (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings via Deep Walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\cite{Perozzi14DeepWalk}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings via LINE - Large Scale Informaiton Network Embeddings \\cite{tang15LINE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Properties**\n",
    "\n",
    "- Graph Types: directed or undirected, weighted or unweighted\n",
    "- Optimizes first-order proximity (i.e. local structures) and second-order proximity (i.e. neighbourhood)\n",
    "- No streaming capability; requires an explicit graph\n",
    "- Optimization such that distribution properties in the graph match distribution properties in the embedding ([Kullback-Leibler Divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence))\n",
    "\n",
    "$$\n",
    "KL(p,q) = \\sum_{i} p(i)\\log{\\frac{p(i)}{q(i)}}\n",
    "$$\n",
    "\n",
    "where $p$ and $q$ are two distributions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach**\n",
    "\n",
    "- Minimize first-order proximity and second-order proximity independently. Concatenate the resulting embedding vectors\n",
    "- First-order proximity is the local pairwise proximity between two vertices $v_1$, $v_2$ linked by an edge $e(v_1,v_2)$, i.e. the weight of the edge $w_{v_1,v_2}$ \n",
    "   - first-order proximity using embeddings \n",
    "   $$\n",
    "   \\mathop{sim_1(i, j)}=\\frac{1}{1+\\exp(u_i^T\\cdot u_j)}\n",
    "   $$\n",
    "   - optimization of \n",
    "   $$\n",
    "   \\mathop{argmin}_{U}{\\;\\mathop{KL}(w_{i,j}, sim_1(i,j))}= \\mathop{argmin}_{U}{\\sum_{e_{i,j}\\in E}{w_{i,j}\\log{sim_1(i,j)}}}\n",
    "   $$\n",
    "- Second-order proximity is the similarity of the neighbourhood of two nodes, i.e. Jaccard Similarity of two nodes (see [Wolfram reference for a good explanation](https://reference.wolfram.com/language/ref/VertexJaccardSimilarity.html))\n",
    "  - Introduce a context vector $u'_j$ per node $v_j \\in V$\n",
    "  - Estimate second oder proximity using embeddings as\n",
    "    $$\n",
    "    \\mathop{sim_2}(j,i) = \\frac{\\exp(u'^T_j\\cdot u_i)}{\\sum_{v_k\\in V}\\exp(u'^T_k\\cdot u_i)}\n",
    "    $$\n",
    "   - optimization of\n",
    "    $$\n",
    "   \\mathop{argmin}_{U}{\\;\\mathop{KL}(Jaccard{i,j}, sim_2(i,j))}= \\mathop{argmin}_{U}{\\sum_{e_{i,j}\\in E}{w_{i,j}\\log{sim_2(i,j)}}}\n",
    "   $$\n",
    "   - Note: in the original formulation they introduced $\\lambda_i$ as modelling the prestige for every node\n",
    "- Optimization is done via Noise Contrastive Estimation\n",
    "- Stochastic Gradient Descent turned out to be problematic when weights have large variance. So they used $w_{i,j}$ as sampling probability of binary edges, i.e. $w_{i,j}=1$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**\n",
    "- Tested on NLP \n",
    "  - Word Analogy Tasks: $LINE>Word2Vec>>DeepWalk$\n",
    "  - Document Classification: $Line>Word2Vec>DeepWalk$\n",
    "- Tested on Social Networks multi-label classification: $LINE\\tilde > DeepWalk$\n",
    "- Tested on Citation Networks multi-label classification: $LINE\\tilde > DeepWalk$\n",
    "- Faster than DeepWalk; Better on more dense graphs; approximatly equal to DeepWalk on sparse graphs\n",
    "\n",
    "Note: Line with SGD only performs very bad\n",
    "\n",
    "- Parameter Sensitivity: performance drops when $d$ gets too large. \n",
    "- Converges faster than DeepWalk (although sampling strategy in DeepWalk is not clear)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "(<a id=\"cit-Perozzi14DeepWalk\" href=\"#call-Perozzi14DeepWalk\">Perozzi, Al-Rfou <em>et al.</em>, 2014</a>) B. Perozzi, R. Al-Rfou and S. Skiena, ``_DeepWalk: Online Learning of Social Representations_'', Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,  2014.  [online](http://doi.acm.org/10.1145/2623330.2623732)\n",
    "\n",
    "(<a id=\"cit-tang15LINE\" href=\"#call-tang15LINE\">Tang, Qu <em>et al.</em>, 2015</a>) J. Tang, M. Qu, M. Wang <em>et al.</em>, ``_LINE: Large-scale Information Network Embedding_'', Proceedings of the 24th International Conference on World Wide Web,  2015.  [online](http://doi.acm.org/10.1145/2736277.2741093)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": false,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
